{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary, Vectorizer, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "        \"\"\"    \n",
    "        # _token_to_idx for text_vocab:\n",
    "        #   {'<MASK>': 0, '<UNK>': 1, '<BEGIN>': 2, '<END>': 3, 'T': 4, 'o': 5, 't': 6, 'a': 7, ....., 'Á': 79}\n",
    "        # _idx_to_token: \n",
    "        #   {0:'<MASK>'0, 1:'<UNK>', 2:'<BEGIN>',   3:'<END>',   4:'T',  5:'o',  6:'t',  7:'a',....., 79:'Á'}\n",
    "            \n",
    "        # _token_to_idx category_vocab: {'Arabic': 0, 'Chinese': 1, ..., 'Vietnamese': 17}\n",
    "        # _idx_to_token:                   {0:'Arabic',  1:'Chinese', ...,  17:'Vietnamese'}\n",
    "\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx         \n",
    "                                                  \n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "            \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        \"\"\"\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    "\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "\n",
    "        self._mask_token = mask_token  # for paddding, e.g., 'McMahan' -> [2, 5, 6, 5, 7, 8, 7, 9, 3, 0, 0, 0, ..., 0]\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)           # mask_index is 0\n",
    "        self.unk_index = self.add_token(self._unk_token)             # unk_index is 1\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token) # begin_seq_index is 2\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)     # end_seq_index is 3\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"   \n",
    "    def __init__(self, text_vocab, category_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text_vocab (Vocabulary): maps characters to integers\n",
    "            category_vocab (Vocabulary): maps nationalities to integers\n",
    "        \"\"\"\n",
    "        self.text_vocab = text_vocab\n",
    "        self.category_vocab = category_vocab\n",
    "\n",
    "    def vectorize(self, text, vector_length=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text (str): the string of characters\n",
    "            vector_length (int): an argument for forcing the length of index vector\n",
    "        \"\"\"        \n",
    "        indices = [self.text_vocab.begin_seq_index]\n",
    "        indices.extend(self.text_vocab.lookup_token(token) \n",
    "                       for token in text.split(\" \"))\n",
    "        indices.append(self.text_vocab.end_seq_index)\n",
    "\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "\n",
    "        out_vector = np.zeros(vector_length, dtype=np.int64)   # SpamDataset._max_seq_length is 19 in current dataset.      \n",
    "        out_vector[:len(indices)] = indices\n",
    "        out_vector[len(indices):] = self.text_vocab.mask_index\n",
    "        \n",
    "        return out_vector, len(indices)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, message_df, cutoff=25):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            message_df(pandas.DataFrame): the target dataset\n",
    "            cutoff (int): frequency threshold for including in Vocabulary \n",
    "        Returns:\n",
    "            an instance of the SpamVectorizer\n",
    "        \"\"\"\n",
    "        category_vocab = Vocabulary()        \n",
    "        for category in sorted(set(message_df.label)):\n",
    "            category_vocab.add_token(category)\n",
    "\n",
    "        word_counts = Counter()\n",
    "        for message in message_df.text:\n",
    "            for token in message.split(\" \"):\n",
    "                    word_counts[token] += 1\n",
    "        \n",
    "        text_vocab = SequenceVocabulary()\n",
    "        for word, word_count in word_counts.items():\n",
    "            if word_count >= cutoff:\n",
    "                text_vocab.add_token(word)\n",
    "        \n",
    "        return cls(text_vocab, category_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, message_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            message_df(pandas.DataFrame): the dataset\n",
    "            vectorizer (SpamVectorizer): vectorizer instatiated from dataset\n",
    "        \"\"\"\n",
    "        self.message_df= message_df\n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        measure_len = lambda context: len(context.split(\" \"))\n",
    "        self._max_seq_length = max(map(measure_len, message_df.text)) + 2\n",
    " \n",
    "        self.train_df = self.message_df[self.message_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.message_df[self.message_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.message_df[self.message_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size), \n",
    "                             'val': (self.val_df, self.validation_size), \n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "        \n",
    "        # Class weights\n",
    "        class_counts = self.train_df.label.value_counts().to_dict()   # {'English': 2972, 'Russian': 2373, ....}\n",
    "        def sort_key(item):\n",
    "            return self._vectorizer.category_vocab.lookup_token(item[0]) # e.g, index of English is 4\n",
    "        sorted_counts = sorted(class_counts.items(), key=sort_key)          # sort by the index number of category_vocab\n",
    "                                   # {('Arabic', 1603), ('Chinese', 220), ('Czech', 414), ('Dutch', 236),('English', 2972), ...}\n",
    "        frequencies = [count for _, count in sorted_counts]\n",
    "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32) # [1/1603, 1/220, 1/414, 1/236, 1/2972, ...]\n",
    "\n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, message_csv):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        \n",
    "        Args:\n",
    "            message_csv (str): location of the dataset\n",
    "        Returns:\n",
    "            an instance of SpamDataset\n",
    "        \"\"\"\n",
    "        message_df= pd.read_csv(message_csv)\n",
    "        train_message_df= message_df[message_df.split=='train']\n",
    "        return cls(message_df, SpamVectorizer.from_dataframe(train_message_df))\n",
    "        \n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's:\n",
    "                features (x_data)\n",
    "                label (y_target)\n",
    "                feature length (x_length)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        text_vector, vec_length = \\\n",
    "            self._vectorizer.vectorize(row.text, self._max_seq_length)\n",
    "        \n",
    "        category_index = \\\n",
    "            self._vectorizer.category_vocab.lookup_token(row.label)\n",
    "\n",
    "        return {'x_data': text_vector,      \n",
    "                'y_target': category_index,            \n",
    "                'x_length': vec_length}        \n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size   \n",
    "\n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "    \n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "         \n",
    "        # If loss worsened\n",
    "        #if loss_t >= loss_tm1:\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def column_gather(y_out, x_lengths):\n",
    "    '''Get a specific vector from each batch datapoint in `y_out`.\n",
    "\n",
    "    More precisely, iterate over batch row indices, get the vector that's at\n",
    "    the position indicated by the corresponding value in `x_lengths` at the row\n",
    "    index.\n",
    "\n",
    "    Args:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, sequence, feature)\n",
    "        x_lengths (torch.LongTensor, torch.cuda.LongTensor)\n",
    "            shape: (batch,)\n",
    "\n",
    "    Returns:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, feature)\n",
    "    '''\n",
    "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1   # deduct 1 since the index starts from 0\n",
    "                                                              # e.g., [9, 6, 11, 9, 7, ...., 12]\n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(x_lengths): # out gets the last hidden vector of each input: (batch, hidden_size)\n",
    "        out.append(y_out[batch_index, column_index]) # e.g., y_out[0, 9], y_out[1, 6]\n",
    "\n",
    "    return torch.stack(out)  # (batch, hidden_size*num_directions); E.g., (64, 64*num_direction)\n",
    "\n",
    "def column_summation(y_out, x_lengths, mode=\"mean\"):\n",
    "    '''Get a max or mean vector from each batch datapoint in `y_out`.\n",
    "\n",
    "    More precisely, iterate over batch row indices, get the max or mean vector of all the vectors by \n",
    "    the position indicated by the corresponding value in `x_lengths` at the row index.\n",
    "\n",
    "    Args:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, sequence, feature)\n",
    "        x_lengths (torch.LongTensor, torch.cuda.LongTensor)\n",
    "            shape: (batch,)\n",
    "        mode: \"mean\" for mean vector; \"max\" for max vector\n",
    "\n",
    "    Returns:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, feature)\n",
    "    '''\n",
    "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n",
    "\n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(x_lengths):\n",
    "        if mode == \"mean\":\n",
    "            # Get the mean vector of the current batch item from y_out and append it to out list.\n",
    "            out.append(y_out[batch_index, :column_index+1].mean(dim=0))\n",
    "        else:\n",
    "            # Get the max vector of the current batch item from y_out and append it to out list.\n",
    "            out.append(y_out[batch_index, :column_index+1].max(dim=0).values)\n",
    "\n",
    "    return torch.stack(out)\n",
    "\n",
    "class SpamClassifier(nn.Module):\n",
    "    \"\"\" A Classifier with an RNN to extract features and an MLP to classify \"\"\"\n",
    "    def __init__(self, embedding_size, num_embeddings, num_classes,\n",
    "                 rnn_hidden_size, bidirectional=False, batch_first=True, padding_idx=0, dropout=0.2):\n",
    "        super(SpamClassifier, self).__init__()\n",
    "\n",
    "        if bidirectional == False:\n",
    "             self.num_directions = 1\n",
    "        else:\n",
    "             self.num_directions = 2\n",
    "        \n",
    "        self.emb = nn.Embedding(num_embeddings=num_embeddings,embedding_dim=embedding_size,padding_idx=padding_idx)          \n",
    "#         self.rnn = nn.RNN(input_size=embedding_size,              \n",
    "        self.rnn = nn.GRU(input_size=embedding_size,\n",
    "#         self.rnn = nn.LSTM(input_size=embedding_size,\n",
    "                             hidden_size=rnn_hidden_size,         \n",
    "                             batch_first=batch_first, \n",
    "                             num_layers = 1,\n",
    "                             dropout = 0.0, \n",
    "                             bidirectional=bidirectional)\n",
    "        \n",
    "        self._dropout_p = dropout\n",
    "        self.fc1 = nn.Linear(in_features=rnn_hidden_size*self.num_directions, out_features=rnn_hidden_size*self.num_directions)\n",
    "        self.fc2 = nn.Linear(in_features=rnn_hidden_size*self.num_directions, out_features=num_classes)                           \n",
    "        self.bn1 = nn.BatchNorm1d(rnn_hidden_size*self.num_directions) \n",
    "\n",
    "    def forward(self, x_in, x_lengths=None, apply_softmax=False):\n",
    "    \n",
    "        x_embedded = self.emb(x_in)            \n",
    "        y_out, _ = self.rnn(x_embedded)  \n",
    "      \n",
    "        if x_lengths is not None:        \n",
    "            y_out = column_summation(y_out, x_lengths, mode=\"mean\") \n",
    "        else:\n",
    "            y_out = y_out[:, -1, :]      \n",
    "            \n",
    "        y_out = F.relu(self.bn1(self.fc1(F.dropout(y_out, self._dropout_p, training=self.training))))  # y_out: (64, 64*num_direction)\n",
    "        y_out = self.fc2(F.dropout(y_out,self._dropout_p, training=self.training))   # y_out: (batch, num_classes) ; (64, 18)\n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out, dim=1)\n",
    "\n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    message_csv=\"./dataset/SMSSpamCollection_Split\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"./model_storage/RNN\",\n",
    "    # Model hyper parameter\n",
    "    char_embedding_size=100,\n",
    "    rnn_hidden_size=32,\n",
    "    bidirectional=True,\n",
    "    dropout=0.4,\n",
    "    # Training hyper parameter\n",
    "    num_epochs=100,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=128,\n",
    "    seed=1337,\n",
    "    early_stopping_criteria=5,\n",
    "    # Runtime hyper parameter\n",
    "    cuda=True,\n",
    "    catch_keyboard_interrupt=True,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    ")\n",
    "\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
    "    \n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [],
   "source": [
    "# create dataset and vectorizer\n",
    "dataset = SpamDataset.load_dataset_and_make_vectorizer(args.message_csv)\n",
    "\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "classifier = SpamClassifier(embedding_size=args.char_embedding_size, \n",
    "                               num_embeddings=len(vectorizer.text_vocab),\n",
    "                               num_classes=len(vectorizer.category_vocab),\n",
    "                               rnn_hidden_size=args.rnn_hidden_size,\n",
    "                               padding_idx=vectorizer.text_vocab.mask_index,\n",
    "                               bidirectional=args.bidirectional,\n",
    "                               dropout=args.dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a445a6ec8e1840758f52fac06398507b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training routine:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb94edaaaf846d182ed5c31333317e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=train:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0873b3c27154ec298c4fcea35d88694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    \n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', total=args.num_epochs, position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------    \n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2. compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'],         # (batch, seq_size) ; e.g., (64,19)\n",
    "                                x_lengths=batch_dict['x_length'])  # (batch,) ; e.g, (64,)\n",
    "                                                                   # y_pred: (batch, num_classes) ; e.g., (64,18)\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "    \n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'], \n",
    "                                x_lengths=batch_dict['x_length'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier, \n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        train_bar.n = 1\n",
    "        val_bar.n = 1\n",
    "        epoch_bar.update()\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss & accuracy on the test set using the best available model\n",
    "\n",
    "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
    "\n",
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "y_pred_list = []         # store predicted values for confusion matrix\n",
    "y_nationality_list = []  # ground truth value\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # compute the output\n",
    "    y_pred =  classifier(batch_dict['x_data'],\n",
    "                         x_lengths=batch_dict['x_length'])\n",
    "\n",
    "    # store predicted values and ground truth values for calculating confusion matrix\n",
    "    y_pred_list.extend(y_pred.max(dim=1)[1].cpu().numpy())\n",
    "    y_nationality_list.extend(batch_dict['y_target'].cpu().numpy())\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.10863878205418587;\n",
      "Test Accuracy: 98.2421875\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
    "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = train_state['train_acc']\n",
    "val_acc = train_state['val_acc']\n",
    "loss = train_state['train_loss']\n",
    "val_loss = train_state['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "5",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
