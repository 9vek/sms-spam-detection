{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "405b62a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (Rule-Based): 85.59%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('./dataset/SMSSpamCollection_Split', sep=',')\n",
    "spam_messages = dataset[(dataset['label'] == 'spam') & ((dataset['split'] == 'train') | (dataset['split'] == 'val'))]['text'].str.cat(sep=' ')\n",
    "ham_messages = dataset[(dataset['label'] == 'ham') & ((dataset['split'] == 'train') | (dataset['split'] == 'val'))]['text'].str.cat(sep=' ')\n",
    "\n",
    "def top_frequency(text, top_n=10):\n",
    "    words = text.split()\n",
    "    word_count = Counter(words)\n",
    "    top_words = word_count.most_common(top_n)\n",
    "    return dict(top_words)\n",
    "\n",
    "top_spam_words = top_frequency(spam_messages, top_n=10)\n",
    "top_ham_words = top_frequency(ham_messages, top_n=10)\n",
    "\n",
    "remove_words=[\"u\",\"ur\",\"txt\"]\n",
    "def rule_based_classification(text, top_spam_words, top_ham_words):\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word.lower() not in remove_words]\n",
    "    word_count = Counter(words)\n",
    "    spam_score = 0\n",
    "    ham_score = 0\n",
    "    \n",
    "#     based on frequency\n",
    "    for word, count in word_count.items():\n",
    "        if word in top_spam_words:\n",
    "            spam_score += 1\n",
    "        if word in top_ham_words:\n",
    "            ham_score += 1\n",
    "\n",
    "#     based on length\n",
    "    if 1 <= len(words) <= 10:\n",
    "        ham_score += 1\n",
    "    elif 10 <len(words)< 30:\n",
    "        spam_score += 1\n",
    "    elif len(words) >= 30:\n",
    "        ham_score += 1\n",
    "        \n",
    "#    make a decison\n",
    "    if spam_score>ham_score:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"ham\"\n",
    "\n",
    "correct_samples = 0\n",
    "total_samples = len(dataset[dataset['split'] == 'test'])\n",
    "for index, row in dataset[dataset['split'] == 'test'].iterrows():\n",
    "    text = row['text']\n",
    "    label = row['label']\n",
    "    predicted_label = rule_based_classification(text, top_spam_words, top_ham_words)\n",
    "    if predicted_label == label:\n",
    "        correct_samples += 1\n",
    "\n",
    "test_accuracy = correct_samples / total_samples\n",
    "\n",
    "print(\"Test Accuracy (Rule-Based): {:.2%}\".format(test_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb0a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
